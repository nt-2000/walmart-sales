{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o7fsFryVOdo"
      },
      "source": [
        "#Importing the walmart csv file from my google drive link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATByZwrEWnB4",
        "outputId": "57ee88f7-a55d-4d84-d37b-320d09131869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.2\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "#Importing all dependencies\n",
        "import pandas as pd\n",
        "print(pd.__version__)\n",
        "df= pd.read_csv('Walmart.csv', encoding_errors='ignore')\n",
        "print(type(df))\n",
        "#encoding errors would ignore any encoding errors that might arise while reading the csv file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLesrbliYl7S",
        "outputId": "b4c53b5e-f7e1-45d1-8d8b-baf62421fd01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10051, 11)\n",
            "   invoice_id   Branch         City                category unit_price  \\\n",
            "0           1  WALM003  San Antonio       Health and beauty     $74.69   \n",
            "1           2  WALM048    Harlingen  Electronic accessories     $15.28   \n",
            "2           3  WALM067  Haltom City      Home and lifestyle     $46.33   \n",
            "3           4  WALM064      Bedford       Health and beauty     $58.22   \n",
            "4           5  WALM013       Irving       Sports and travel     $86.31   \n",
            "\n",
            "   quantity        date      time payment_method  rating  profit_margin  \n",
            "0       7.0  05-01-2019  13:08:00        Ewallet     9.1           0.48  \n",
            "1       5.0  08-03-2019  10:29:00           Cash     9.6           0.48  \n",
            "2       7.0  03-03-2019  13:23:00    Credit card     7.4           0.33  \n",
            "3       8.0  27-01-2019  20:33:00        Ewallet     8.4           0.33  \n",
            "4       7.0  08-02-2019  10:37:00        Ewallet     5.3           0.48  \n",
            "\n",
            "\n",
            "\n",
            "         invoice_id      quantity        rating  profit_margin\n",
            "count  10051.000000  10020.000000  10051.000000   10051.000000\n",
            "mean    5025.741220      2.353493      5.825659       0.393791\n",
            "std     2901.174372      1.602658      1.763991       0.090669\n",
            "min        1.000000      1.000000      3.000000       0.180000\n",
            "25%     2513.500000      1.000000      4.000000       0.330000\n",
            "50%     5026.000000      2.000000      6.000000       0.330000\n",
            "75%     7538.500000      3.000000      7.000000       0.480000\n",
            "max    10000.000000     10.000000     10.000000       0.570000\n"
          ]
        }
      ],
      "source": [
        "#displaying the number of rows and columns in the file\n",
        "print(df.shape)\n",
        "\n",
        "#displaying the first five rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "print('\\n\\n')\n",
        "#description of the entire data\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx8eDVTNe7fc"
      },
      "source": [
        "Now there are a couple of things to be taken into consideration. When we use describe method we can see that the column quantity doesn't have 10051 values , that means there are some missing values.\n",
        "\n",
        "Next, unit price is not a numerical column and hence it is not included in the list of columns in describe function output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdi5PABpfXcA",
        "outputId": "a013d27b-5b09-4d94-9d5d-7e1f0086b6f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10051 entries, 0 to 10050\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   invoice_id      10051 non-null  int64  \n",
            " 1   Branch          10051 non-null  object \n",
            " 2   City            10051 non-null  object \n",
            " 3   category        10051 non-null  object \n",
            " 4   unit_price      10020 non-null  object \n",
            " 5   quantity        10020 non-null  float64\n",
            " 6   date            10051 non-null  object \n",
            " 7   time            10051 non-null  object \n",
            " 8   payment_method  10051 non-null  object \n",
            " 9   rating          10051 non-null  float64\n",
            " 10  profit_margin   10051 non-null  float64\n",
            "dtypes: float64(3), int64(1), object(7)\n",
            "memory usage: 863.9+ KB\n"
          ]
        }
      ],
      "source": [
        "#checking the data type of columns in the dataframe\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JXRmULMf6Zv"
      },
      "source": [
        "Here , we can observe that the unit price and quantity columns have missing data in the csv file. Also unit price is an object and not an integer which would make it difficult for us to perform operations on the unit price data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDVVJoEKgYHX",
        "outputId": "0e3e2d6c-84e8-42ba-c400-4d4eea55ddeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51\n"
          ]
        }
      ],
      "source": [
        "#checking for duplicate records in the file\n",
        "df.duplicated() #will return boolean value for each row whether it is duplicated or not\n",
        "\n",
        "#finding the total sum of duplicated records\n",
        "print(df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI65y8YYg2HM"
      },
      "source": [
        "Here, we have found out that we have duplicate values in our file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "bWXkldoOg7Yv",
        "outputId": "1fb1c26e-7713-4222-e545-b327dbf21bc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "invoice_id         0\n",
              "Branch             0\n",
              "City               0\n",
              "category           0\n",
              "unit_price        31\n",
              "quantity          31\n",
              "date               0\n",
              "time               0\n",
              "payment_method     0\n",
              "rating             0\n",
              "profit_margin      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checking for missing values in the file\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zu72NE4rU5g",
        "outputId": "de1794c8-aaa0-4cb0-e894-d6e635b3522e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "(10000, 11)\n"
          ]
        }
      ],
      "source": [
        "#removing all the duplicate records in the file\n",
        "df.drop_duplicates(inplace=True)\n",
        "#inplace=True will make sure that the new records wherein all the duplicate values have been removed will be stored in the same dataframe itself and won't return a new object\n",
        "\n",
        "#check for duplicates once again\n",
        "print(df.duplicated().sum())\n",
        "\n",
        "#checking the shape of the file\n",
        "print(df.shape)\n",
        "#Here the shape(specifically the rows) got reduced because the duplicate records were all removed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BO1d4HA_p2K"
      },
      "source": [
        "Now we have solved the duplicating issue by removing them. Now we have to deal with null values. We can see that there are 31 records where quantity and unit price have null values. Since it is difficult for us to understand the quantity and unit price we will drop those records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7XQQMDTAAub",
        "outputId": "735fec7a-8e5e-4c2c-ca80-76f1313a5f95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "invoice_id        0\n",
            "Branch            0\n",
            "City              0\n",
            "category          0\n",
            "unit_price        0\n",
            "quantity          0\n",
            "date              0\n",
            "time              0\n",
            "payment_method    0\n",
            "rating            0\n",
            "profit_margin     0\n",
            "dtype: int64\n",
            "(9969, 11)\n"
          ]
        }
      ],
      "source": [
        "#dropping the records with null values (quantity and unit price)\n",
        "df.dropna(inplace=True)\n",
        "#inplace=True will make sure that the new records wherein all the null values have been removed will be stored in the same dataframe itself and won't return a new object\n",
        "\n",
        "#checking if there are any more null values in the file\n",
        "print(df.isnull().sum())\n",
        "\n",
        "#checking the shape of the file after the null values are removed\n",
        "print(df.shape)\n",
        "#The shape(especially the rows) would be reduced even further since the null records have been dropped from the data frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8b82cwpB2JP"
      },
      "source": [
        "#Converting the string datatype of unit price into float for analysis purposes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htmE_VnHtiKw"
      },
      "source": [
        "Here, we can observe that the values for unit price has dollar in them. So it is not easy to convert the unit price directly to float values. For this reason, we will first have to replace the dollar sign with empty string and then carry out the typecasting to float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Petcch5Rtp6o",
        "outputId": "ffccf0e2-8b7c-4652-be29-e903a81129fe"
      },
      "outputs": [],
      "source": [
        "#replacing the $ sign and then coverting it into float\n",
        "df['unit_price']=df['unit_price'].str.replace('$','').astype('float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRUf85aluf4s",
        "outputId": "d26b135a-01e7-4e8e-9a69-46402f698209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   invoice_id   Branch         City                category  unit_price  \\\n",
            "0           1  WALM003  San Antonio       Health and beauty       74.69   \n",
            "1           2  WALM048    Harlingen  Electronic accessories       15.28   \n",
            "2           3  WALM067  Haltom City      Home and lifestyle       46.33   \n",
            "3           4  WALM064      Bedford       Health and beauty       58.22   \n",
            "4           5  WALM013       Irving       Sports and travel       86.31   \n",
            "\n",
            "   quantity        date      time payment_method  rating  profit_margin  \n",
            "0       7.0  05-01-2019  13:08:00        Ewallet     9.1           0.48  \n",
            "1       5.0  08-03-2019  10:29:00           Cash     9.6           0.48  \n",
            "2       7.0  03-03-2019  13:23:00    Credit card     7.4           0.33  \n",
            "3       8.0  27-01-2019  20:33:00        Ewallet     8.4           0.33  \n",
            "4       7.0  08-02-2019  10:37:00        Ewallet     5.3           0.48  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 9969 entries, 0 to 9999\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   invoice_id      9969 non-null   int64  \n",
            " 1   Branch          9969 non-null   object \n",
            " 2   City            9969 non-null   object \n",
            " 3   category        9969 non-null   object \n",
            " 4   unit_price      9969 non-null   float64\n",
            " 5   quantity        9969 non-null   float64\n",
            " 6   date            9969 non-null   object \n",
            " 7   time            9969 non-null   object \n",
            " 8   payment_method  9969 non-null   object \n",
            " 9   rating          9969 non-null   float64\n",
            " 10  profit_margin   9969 non-null   float64\n",
            "dtypes: float64(4), int64(1), object(6)\n",
            "memory usage: 934.6+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#checking whether the typecast changes are visible in the dataframe\n",
        "print(df.head())\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVF14749vNH0"
      },
      "source": [
        "#Addition of a new column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwWg7Dq7vSCB"
      },
      "source": [
        "Now in our dataset we don't have a specific column indicating the total price or total amount for the number of quantities that each category has. As of now we only have the unit price and the quantities. So for that purpose we will create a new column called total amount."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytLF_vwjvp0_",
        "outputId": "dc177725-5220-4601-85dc-74b5394ddefc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['invoice_id', 'Branch', 'City', 'category', 'unit_price', 'quantity',\n",
            "       'date', 'time', 'payment_method', 'rating', 'profit_margin'],\n",
            "      dtype='object')\n",
            "   invoice_id   Branch         City                category  unit_price  \\\n",
            "0           1  WALM003  San Antonio       Health and beauty       74.69   \n",
            "1           2  WALM048    Harlingen  Electronic accessories       15.28   \n",
            "2           3  WALM067  Haltom City      Home and lifestyle       46.33   \n",
            "3           4  WALM064      Bedford       Health and beauty       58.22   \n",
            "4           5  WALM013       Irving       Sports and travel       86.31   \n",
            "\n",
            "   quantity        date      time payment_method  rating  profit_margin  \\\n",
            "0       7.0  05-01-2019  13:08:00        Ewallet     9.1           0.48   \n",
            "1       5.0  08-03-2019  10:29:00           Cash     9.6           0.48   \n",
            "2       7.0  03-03-2019  13:23:00    Credit card     7.4           0.33   \n",
            "3       8.0  27-01-2019  20:33:00        Ewallet     8.4           0.33   \n",
            "4       7.0  08-02-2019  10:37:00        Ewallet     5.3           0.48   \n",
            "\n",
            "    total  \n",
            "0  522.83  \n",
            "1   76.40  \n",
            "2  324.31  \n",
            "3  465.76  \n",
            "4  604.17  \n"
          ]
        }
      ],
      "source": [
        "#Checking and creating the new column based on unit price and quantity\n",
        "print(df.columns)\n",
        "df['total']= df['unit_price'] * df['quantity']\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmN2mwRQyUNh"
      },
      "source": [
        "#Connecting the python to mysql"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQqU4KxeyZOS"
      },
      "source": [
        "Now we want to carry out our further analysis through mysql and for that we need to connect our python to mysql. We need to install python libraries like pymysql and sqlalchemy for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVKdNO_Gyp8H",
        "outputId": "480eb16c-1ffb-4653-f098-8c575b454c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
            "   --------------------------- ------------ 30.7/45.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 45.0/45.0 kB 445.3 kB/s eta 0:00:00\n",
            "Installing collected packages: pymysql\n",
            "Successfully installed pymysql-1.1.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: sqlalchemy in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.0.30)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "#installing pymysql and sqlalchemy packages\n",
        "\n",
        "%pip install pymysql\n",
        "%pip install sqlalchemy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orR532rt1l5F",
        "outputId": "06727bda-61a1-48eb-a417-3d066ef7020a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: PyMySQL\n",
            "Version: 1.1.1\n",
            "Summary: Pure Python MySQL Driver\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Inada Naoki <songofacandy@gmail.com>, Yutaka Matsubara <yutaka.matsubara@gmail.com>\n",
            "License: MIT License\n",
            "Location: c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\n",
            "Requires: \n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Name: SQLAlchemy\n",
            "Version: 2.0.30\n",
            "Summary: Database Abstraction Library\n",
            "Home-page: https://www.sqlalchemy.org\n",
            "Author: Mike Bayer\n",
            "Author-email: mike_mp@zzzcomputing.com\n",
            "License: MIT\n",
            "Location: c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\n",
            "Requires: greenlet, typing-extensions\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "#checking whether both the packages are correctly installed\n",
        "%pip show pymysql\n",
        "%pip show sqlalchemy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "O_1OYmRq15Pm"
      },
      "outputs": [],
      "source": [
        "#import dependencies for pymysql and sqlalchemy\n",
        "import pymysql #this will work as an adapter, connecting our python with mysql\n",
        "from sqlalchemy import create_engine #this also establishes a connection with sql, but this gives us provision to work with python objects rather than raw sql queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEa9xYzP4inw"
      },
      "source": [
        "Now before establishing a connection between python and mysql, we need to know a few things about our mysql connection\n",
        "\n",
        "\n",
        "\n",
        "*   host=localhost (Since the mysql server is on my local machine itself)\n",
        "*   port= 3306 (the port where the mysql server is running)\n",
        "*   user = root (username of my mysql server)\n",
        "*   password = admin (password of my mysql server)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOt6guq15JMH",
        "outputId": "53aa867f-c59c-45d4-e4bb-5aefebe9e736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on method to_sql in module pandas.core.generic:\n",
            "\n",
            "to_sql(name: 'str', con, *, schema: 'str | None' = None, if_exists: \"Literal['fail', 'replace', 'append']\" = 'fail', index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, chunksize: 'int | None' = None, dtype: 'DtypeArg | None' = None, method: \"Literal['multi'] | Callable | None\" = None) -> 'int | None' method of pandas.core.frame.DataFrame instance\n",
            "    Write records stored in a DataFrame to a SQL database.\n",
            "\n",
            "    Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
            "    newly created, appended to, or overwritten.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    name : str\n",
            "        Name of SQL table.\n",
            "    con : sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection\n",
            "        Using SQLAlchemy makes it possible to use any DB supported by that\n",
            "        library. Legacy support is provided for sqlite3.Connection objects. The user\n",
            "        is responsible for engine disposal and connection closure for the SQLAlchemy\n",
            "        connectable. See `here                 <https://docs.sqlalchemy.org/en/20/core/connections.html>`_.\n",
            "        If passing a sqlalchemy.engine.Connection which is already in a transaction,\n",
            "        the transaction will not be committed.  If passing a sqlite3.Connection,\n",
            "        it will not be possible to roll back the record insertion.\n",
            "\n",
            "    schema : str, optional\n",
            "        Specify the schema (if database flavor supports this). If None, use\n",
            "        default schema.\n",
            "    if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
            "        How to behave if the table already exists.\n",
            "\n",
            "        * fail: Raise a ValueError.\n",
            "        * replace: Drop the table before inserting new values.\n",
            "        * append: Insert new values to the existing table.\n",
            "\n",
            "    index : bool, default True\n",
            "        Write DataFrame index as a column. Uses `index_label` as the column\n",
            "        name in the table. Creates a table index for this column.\n",
            "    index_label : str or sequence, default None\n",
            "        Column label for index column(s). If None is given (default) and\n",
            "        `index` is True, then the index names are used.\n",
            "        A sequence should be given if the DataFrame uses MultiIndex.\n",
            "    chunksize : int, optional\n",
            "        Specify the number of rows in each batch to be written at a time.\n",
            "        By default, all rows will be written at once.\n",
            "    dtype : dict or scalar, optional\n",
            "        Specifying the datatype for columns. If a dictionary is used, the\n",
            "        keys should be the column names and the values should be the\n",
            "        SQLAlchemy types or strings for the sqlite3 legacy mode. If a\n",
            "        scalar is provided, it will be applied to all columns.\n",
            "    method : {None, 'multi', callable}, optional\n",
            "        Controls the SQL insertion clause used:\n",
            "\n",
            "        * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
            "        * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
            "        * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
            "\n",
            "        Details and a sample callable implementation can be found in the\n",
            "        section :ref:`insert method <io.sql.method>`.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    None or int\n",
            "        Number of rows affected by to_sql. None is returned if the callable\n",
            "        passed into ``method`` does not return an integer number of rows.\n",
            "\n",
            "        The number of returned rows affected is the sum of the ``rowcount``\n",
            "        attribute of ``sqlite3.Cursor`` or SQLAlchemy connectable which may not\n",
            "        reflect the exact number of written rows as stipulated in the\n",
            "        `sqlite3 <https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.rowcount>`__ or\n",
            "        `SQLAlchemy <https://docs.sqlalchemy.org/en/20/core/connections.html#sqlalchemy.engine.CursorResult.rowcount>`__.\n",
            "\n",
            "        .. versionadded:: 1.4.0\n",
            "\n",
            "    Raises\n",
            "    ------\n",
            "    ValueError\n",
            "        When the table already exists and `if_exists` is 'fail' (the\n",
            "        default).\n",
            "\n",
            "    See Also\n",
            "    --------\n",
            "    read_sql : Read a DataFrame from a table.\n",
            "\n",
            "    Notes\n",
            "    -----\n",
            "    Timezone aware datetime columns will be written as\n",
            "    ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n",
            "    database. Otherwise, the datetimes will be stored as timezone unaware\n",
            "    timestamps local to the original timezone.\n",
            "\n",
            "    Not all datastores support ``method=\"multi\"``. Oracle, for example,\n",
            "    does not support multi-value insert.\n",
            "\n",
            "    References\n",
            "    ----------\n",
            "    .. [1] https://docs.sqlalchemy.org\n",
            "    .. [2] https://www.python.org/dev/peps/pep-0249/\n",
            "\n",
            "    Examples\n",
            "    --------\n",
            "    Create an in-memory SQLite database.\n",
            "\n",
            "    >>> from sqlalchemy import create_engine\n",
            "    >>> engine = create_engine('sqlite://', echo=False)\n",
            "\n",
            "    Create a table from scratch with 3 rows.\n",
            "\n",
            "    >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
            "    >>> df\n",
            "         name\n",
            "    0  User 1\n",
            "    1  User 2\n",
            "    2  User 3\n",
            "\n",
            "    >>> df.to_sql(name='users', con=engine)\n",
            "    3\n",
            "    >>> from sqlalchemy import text\n",
            "    >>> with engine.connect() as conn:\n",
            "    ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
            "    [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
            "\n",
            "    An `sqlalchemy.engine.Connection` can also be passed to `con`:\n",
            "\n",
            "    >>> with engine.begin() as connection:\n",
            "    ...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
            "    ...     df1.to_sql(name='users', con=connection, if_exists='append')\n",
            "    2\n",
            "\n",
            "    This is allowed to support operations that require that the same\n",
            "    DBAPI connection is used for the entire operation.\n",
            "\n",
            "    >>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})\n",
            "    >>> df2.to_sql(name='users', con=engine, if_exists='append')\n",
            "    2\n",
            "    >>> with engine.connect() as conn:\n",
            "    ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
            "    [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
            "     (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),\n",
            "     (1, 'User 7')]\n",
            "\n",
            "    Overwrite the table with just ``df2``.\n",
            "\n",
            "    >>> df2.to_sql(name='users', con=engine, if_exists='replace',\n",
            "    ...            index_label='id')\n",
            "    2\n",
            "    >>> with engine.connect() as conn:\n",
            "    ...    conn.execute(text(\"SELECT * FROM users\")).fetchall()\n",
            "    [(0, 'User 6'), (1, 'User 7')]\n",
            "\n",
            "    Use ``method`` to define a callable insertion method to do nothing\n",
            "    if there's a primary key conflict on a table in a PostgreSQL database.\n",
            "\n",
            "    >>> from sqlalchemy.dialects.postgresql import insert\n",
            "    >>> def insert_on_conflict_nothing(table, conn, keys, data_iter):\n",
            "    ...     # \"a\" is the primary key in \"conflict_table\"\n",
            "    ...     data = [dict(zip(keys, row)) for row in data_iter]\n",
            "    ...     stmt = insert(table.table).values(data).on_conflict_do_nothing(index_elements=[\"a\"])\n",
            "    ...     result = conn.execute(stmt)\n",
            "    ...     return result.rowcount\n",
            "    >>> df_conflict.to_sql(name=\"conflict_table\", con=conn, if_exists=\"append\", method=insert_on_conflict_nothing)  # doctest: +SKIP\n",
            "    0\n",
            "\n",
            "    For MySQL, a callable to update columns ``b`` and ``c`` if there's a conflict\n",
            "    on a primary key.\n",
            "\n",
            "    >>> from sqlalchemy.dialects.mysql import insert\n",
            "    >>> def insert_on_conflict_update(table, conn, keys, data_iter):\n",
            "    ...     # update columns \"b\" and \"c\" on primary key conflict\n",
            "    ...     data = [dict(zip(keys, row)) for row in data_iter]\n",
            "    ...     stmt = (\n",
            "    ...         insert(table.table)\n",
            "    ...         .values(data)\n",
            "    ...     )\n",
            "    ...     stmt = stmt.on_duplicate_key_update(b=stmt.inserted.b, c=stmt.inserted.c)\n",
            "    ...     result = conn.execute(stmt)\n",
            "    ...     return result.rowcount\n",
            "    >>> df_conflict.to_sql(name=\"conflict_table\", con=conn, if_exists=\"append\", method=insert_on_conflict_update)  # doctest: +SKIP\n",
            "    2\n",
            "\n",
            "    Specify the dtype (especially useful for integers with missing values).\n",
            "    Notice that while pandas is forced to store the data as floating point,\n",
            "    the database supports nullable integers. When fetching the data with\n",
            "    Python, we get back integer scalars.\n",
            "\n",
            "    >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
            "    >>> df\n",
            "         A\n",
            "    0  1.0\n",
            "    1  NaN\n",
            "    2  2.0\n",
            "\n",
            "    >>> from sqlalchemy.types import Integer\n",
            "    >>> df.to_sql(name='integers', con=engine, index=False,\n",
            "    ...           dtype={\"A\": Integer()})\n",
            "    3\n",
            "\n",
            "    >>> with engine.connect() as conn:\n",
            "    ...   conn.execute(text(\"SELECT * FROM integers\")).fetchall()\n",
            "    [(1,), (None,), (2,)]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(df.to_sql)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "E6xAa0-s8674",
        "outputId": "2183d549-b8d3-46bb-ee3b-73a672ab264e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connection Successful\n"
          ]
        }
      ],
      "source": [
        "import pymysql\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "     # Update connection string with your correct credentials\n",
        "engine_mysql = create_engine('mysql+pymysql://root:admin@localhost:3306/walmart_db')\n",
        "# engine = create_engine(\"mysql+pymysql://user:pw@host/db\", pool_pre_ping=True)\n",
        "\n",
        "try:\n",
        "    engine_mysql\n",
        "    print('Connection Successful')\n",
        "except:\n",
        "         print('Connection Failed')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOnVMqG_-dat"
      },
      "source": [
        "After the connection is successful, we have to export the walmart dataframe to our sql database walmart_db inside our mysql. The engine is already established through create_engine and now we have to export the dataframe using that engine_mysql."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "0POc4MXk-xgj",
        "outputId": "65157a3c-ebc1-46ab-bfb8-f415ce9d902e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9969"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#exporting the dataframe to sql database\n",
        "df.to_sql(name='walmart', con=engine_mysql, if_exists='append', index=False)\n",
        "\n",
        "#name suggests the name of the table that would be created in the mysql database.\n",
        "#if_exists suggests what action to be taken if the table already exists. In this case, the table data will be appended if the table already exists.\n",
        "#Index refers to the index number 1,2,3,4 that is present in the dataframe. In this case, we don't want to export the index along with other details of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9969, 12)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
